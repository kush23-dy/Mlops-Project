{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "fc932af1-e0eb-40d2-88d2-7dc955d9c648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a77843e7-5027-4bab-b234-a2352ff9fa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"balanced_audio_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5eaaae3d-7133-4f22-b722-ff1e02abfec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc_1</th>\n",
       "      <th>mfcc_2</th>\n",
       "      <th>mfcc_3</th>\n",
       "      <th>mfcc_4</th>\n",
       "      <th>mfcc_5</th>\n",
       "      <th>mfcc_6</th>\n",
       "      <th>mfcc_7</th>\n",
       "      <th>mfcc_8</th>\n",
       "      <th>mfcc_9</th>\n",
       "      <th>mfcc_10</th>\n",
       "      <th>mfcc_11</th>\n",
       "      <th>mfcc_12</th>\n",
       "      <th>mfcc_13</th>\n",
       "      <th>energy</th>\n",
       "      <th>zcr</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-477.95420</td>\n",
       "      <td>256.916440</td>\n",
       "      <td>67.115460</td>\n",
       "      <td>8.739448</td>\n",
       "      <td>2.758284</td>\n",
       "      <td>0.770825</td>\n",
       "      <td>5.305133</td>\n",
       "      <td>6.250667</td>\n",
       "      <td>0.596355</td>\n",
       "      <td>-0.712356</td>\n",
       "      <td>1.323257</td>\n",
       "      <td>2.500952</td>\n",
       "      <td>4.866691</td>\n",
       "      <td>0.023121</td>\n",
       "      <td>0.025192</td>\n",
       "      <td>341.103629</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-270.60608</td>\n",
       "      <td>42.222730</td>\n",
       "      <td>-48.578365</td>\n",
       "      <td>19.939613</td>\n",
       "      <td>5.550137</td>\n",
       "      <td>17.706486</td>\n",
       "      <td>-11.928199</td>\n",
       "      <td>25.873552</td>\n",
       "      <td>-16.771667</td>\n",
       "      <td>1.831336</td>\n",
       "      <td>-8.294287</td>\n",
       "      <td>1.411134</td>\n",
       "      <td>5.032603</td>\n",
       "      <td>0.021516</td>\n",
       "      <td>0.220474</td>\n",
       "      <td>2328.221006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-131.91475</td>\n",
       "      <td>148.794920</td>\n",
       "      <td>13.958692</td>\n",
       "      <td>68.573760</td>\n",
       "      <td>0.653590</td>\n",
       "      <td>-12.121082</td>\n",
       "      <td>-0.728478</td>\n",
       "      <td>3.060145</td>\n",
       "      <td>6.074419</td>\n",
       "      <td>6.081366</td>\n",
       "      <td>-3.391458</td>\n",
       "      <td>-1.216702</td>\n",
       "      <td>1.177939</td>\n",
       "      <td>0.159142</td>\n",
       "      <td>0.048676</td>\n",
       "      <td>932.352704</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-480.88986</td>\n",
       "      <td>262.513430</td>\n",
       "      <td>66.892426</td>\n",
       "      <td>8.498765</td>\n",
       "      <td>2.202479</td>\n",
       "      <td>1.525443</td>\n",
       "      <td>4.453030</td>\n",
       "      <td>4.999896</td>\n",
       "      <td>-0.053064</td>\n",
       "      <td>-1.211203</td>\n",
       "      <td>1.451995</td>\n",
       "      <td>2.073047</td>\n",
       "      <td>5.178939</td>\n",
       "      <td>0.024008</td>\n",
       "      <td>0.023468</td>\n",
       "      <td>333.384016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-413.69970</td>\n",
       "      <td>37.239326</td>\n",
       "      <td>2.051036</td>\n",
       "      <td>16.639393</td>\n",
       "      <td>-2.405408</td>\n",
       "      <td>19.127040</td>\n",
       "      <td>-3.345035</td>\n",
       "      <td>4.515248</td>\n",
       "      <td>7.415859</td>\n",
       "      <td>4.109774</td>\n",
       "      <td>-1.621489</td>\n",
       "      <td>2.398941</td>\n",
       "      <td>-0.977538</td>\n",
       "      <td>0.006376</td>\n",
       "      <td>0.237839</td>\n",
       "      <td>2733.993469</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mfcc_1      mfcc_2     mfcc_3     mfcc_4    mfcc_5     mfcc_6  \\\n",
       "0 -477.95420  256.916440  67.115460   8.739448  2.758284   0.770825   \n",
       "1 -270.60608   42.222730 -48.578365  19.939613  5.550137  17.706486   \n",
       "2 -131.91475  148.794920  13.958692  68.573760  0.653590 -12.121082   \n",
       "3 -480.88986  262.513430  66.892426   8.498765  2.202479   1.525443   \n",
       "4 -413.69970   37.239326   2.051036  16.639393 -2.405408  19.127040   \n",
       "\n",
       "      mfcc_7     mfcc_8     mfcc_9   mfcc_10   mfcc_11   mfcc_12   mfcc_13  \\\n",
       "0   5.305133   6.250667   0.596355 -0.712356  1.323257  2.500952  4.866691   \n",
       "1 -11.928199  25.873552 -16.771667  1.831336 -8.294287  1.411134  5.032603   \n",
       "2  -0.728478   3.060145   6.074419  6.081366 -3.391458 -1.216702  1.177939   \n",
       "3   4.453030   4.999896  -0.053064 -1.211203  1.451995  2.073047  5.178939   \n",
       "4  -3.345035   4.515248   7.415859  4.109774 -1.621489  2.398941 -0.977538   \n",
       "\n",
       "     energy       zcr  spectral_centroid  label  \n",
       "0  0.023121  0.025192         341.103629      0  \n",
       "1  0.021516  0.220474        2328.221006      0  \n",
       "2  0.159142  0.048676         932.352704      1  \n",
       "3  0.024008  0.023468         333.384016      0  \n",
       "4  0.006376  0.237839        2733.993469      0  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "32c18fa4-3f0c-459e-866c-5341586d0b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"label\", axis=1)\n",
    "y = df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "97fc8d17-16c8-4f88-a4ee-1fce35f95c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a3769dfb-a497-492a-a969-0d9148660e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scale = StandardScaler()\n",
    "X_train_Scaled = scale.fit_transform(X_train)\n",
    "X_test_scaled = scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864dce70-dc36-4ffd-a97c-bbf974f182f0",
   "metadata": {},
   "source": [
    "# Logisitc Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e3e65f8-d590-48bf-b686-e75fa7d8e9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(max_iter = 10000)\n",
    "model.fit(X_train_Scaled, y_train)\n",
    "\n",
    "y_pred_test = model.predict(X_test_scaled)\n",
    "y_pred_train = model.predict(X_train_Scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9f847a58-f1fe-498b-89db-5ef3dbc92495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuaracy for training Dataset :-  0.9901630685944411\n",
      "Accuracy for Test Data :-  0.991418008978083\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      3808\n",
      "           1       0.99      1.00      0.99      3766\n",
      "\n",
      "    accuracy                           0.99      7574\n",
      "   macro avg       0.99      0.99      0.99      7574\n",
      "weighted avg       0.99      0.99      0.99      7574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(\"Accuaracy for training Dataset :- \", accuracy_score(y_pred_train, y_train))\n",
    "print(\"Accuracy for Test Data :- \", accuracy_score(y_pred_test, y_test))\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_pred_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "14666558-753b-4202-9d7c-7abf58d7976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from collections import deque\n",
    "\n",
    "def advanced_vad(file_path, model, scaler):\n",
    "    \n",
    "    y, sr = librosa.load(file_path, sr=22050)\n",
    "    window_duration = 0.5   \n",
    "    overlap_ratio = 0.5    \n",
    "    \n",
    "    window_samples = int(sr * window_duration)\n",
    "    hop_samples = int(window_samples * (1 - overlap_ratio))\n",
    "    \n",
    "    frame_length = 2048\n",
    "    hop_length = 512\n",
    "    \n",
    "    enter_threshold = 0.7\n",
    "    exit_threshold = 0.3\n",
    "\n",
    "    smoothing_buffer = deque(maxlen=3)\n",
    "\n",
    "    current_state = \"Noise\"\n",
    "    \n",
    "    print(\"\\nAdvanced VAD Processing...\\n\")\n",
    "    \n",
    "    window_count = 0\n",
    "    \n",
    "    for start in range(0, len(y) - window_samples, hop_samples):\n",
    "        \n",
    "        window_count += 1\n",
    "        \n",
    "        chunk = y[start:start + window_samples]\n",
    "\n",
    "        mfcc = librosa.feature.mfcc(\n",
    "            y=chunk, sr=sr, n_mfcc=13,\n",
    "            n_fft=frame_length,\n",
    "            hop_length=hop_length\n",
    "        )\n",
    "        \n",
    "        energy = librosa.feature.rms(\n",
    "            y=chunk,\n",
    "            frame_length=frame_length,\n",
    "            hop_length=hop_length\n",
    "        )\n",
    "        \n",
    "        zcr = librosa.feature.zero_crossing_rate(\n",
    "            chunk,\n",
    "            frame_length=frame_length,\n",
    "            hop_length=hop_length\n",
    "        )\n",
    "        \n",
    "        spectral_centroid = librosa.feature.spectral_centroid(\n",
    "            y=chunk, sr=sr,\n",
    "            n_fft=frame_length,\n",
    "            hop_length=hop_length\n",
    "        )\n",
    "        \n",
    "        features = np.vstack([\n",
    "            mfcc,\n",
    "            energy,\n",
    "            zcr,\n",
    "            spectral_centroid\n",
    "        ]).T\n",
    "        \n",
    "        features_scaled = scaler.transform(features)\n",
    "        \n",
    "        probs = model.predict_proba(features_scaled)[:, 1]\n",
    "        speech_ratio = np.mean(probs)\n",
    "        smoothing_buffer.append(speech_ratio)\n",
    "        smoothed_ratio = np.mean(smoothing_buffer)\n",
    "\n",
    "        if current_state == \"Noise\":\n",
    "            if smoothed_ratio > enter_threshold:\n",
    "                current_state = \"Speech\"\n",
    "        \n",
    "        elif current_state == \"Speech\":\n",
    "            if smoothed_ratio < exit_threshold:\n",
    "                current_state = \"Noise\"\n",
    "        \n",
    "        print(f\"Window {window_count}: {current_state} | Prob: {round(smoothed_ratio,3)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "59f290fd-d69e-41cd-9481-8095b7c80ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vikas\\AppData\\Local\\Temp\\ipykernel_31088\\3077679620.py:7: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(file_path, sr=22050)\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Advanced VAD Processing...\n",
      "\n",
      "Window 1: Noise | Prob: 0.0\n",
      "Window 2: Noise | Prob: 0.001\n",
      "Window 3: Noise | Prob: 0.001\n",
      "Window 4: Noise | Prob: 0.002\n",
      "Window 5: Noise | Prob: 0.003\n",
      "Window 6: Noise | Prob: 0.005\n",
      "Window 7: Noise | Prob: 0.004\n",
      "Window 8: Noise | Prob: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 9: Noise | Prob: 0.004\n",
      "Window 10: Noise | Prob: 0.005\n",
      "Window 11: Noise | Prob: 0.004\n",
      "Window 12: Noise | Prob: 0.003\n",
      "Window 13: Noise | Prob: 0.002\n",
      "Window 14: Noise | Prob: 0.004\n",
      "Window 15: Noise | Prob: 0.007\n",
      "Window 16: Noise | Prob: 0.01\n",
      "Window 17: Noise | Prob: 0.009\n",
      "Window 18: Noise | Prob: 0.008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 19: Noise | Prob: 0.019\n",
      "Window 20: Noise | Prob: 0.023\n",
      "Window 21: Noise | Prob: 0.1\n",
      "Window 22: Noise | Prob: 0.296\n",
      "Window 23: Noise | Prob: 0.556\n",
      "Window 24: Noise | Prob: 0.63\n",
      "Window 25: Noise | Prob: 0.478\n",
      "Window 26: Noise | Prob: 0.226\n",
      "Window 27: Noise | Prob: 0.102\n",
      "Window 28: Noise | Prob: 0.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 29: Noise | Prob: 0.049\n",
      "Window 30: Noise | Prob: 0.019\n",
      "Window 31: Noise | Prob: 0.031\n",
      "Window 32: Noise | Prob: 0.065\n",
      "Window 33: Noise | Prob: 0.085\n",
      "Window 34: Noise | Prob: 0.15\n",
      "Window 35: Noise | Prob: 0.376\n",
      "Window 36: Noise | Prob: 0.688\n",
      "Window 37: Speech | Prob: 0.928\n",
      "Window 38: Speech | Prob: 0.878\n",
      "Window 39: Speech | Prob: 0.575\n",
      "Window 40: Noise | Prob: 0.242\n",
      "Window 41: Noise | Prob: 0.042\n",
      "Window 42: Noise | Prob: 0.014\n",
      "Window 43: Noise | Prob: 0.102\n",
      "Window 44: Noise | Prob: 0.278\n",
      "Window 45: Noise | Prob: 0.42\n",
      "Window 46: Noise | Prob: 0.379\n",
      "\n",
      "Detection Completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vikas\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "advanced_vad(\"noise.mp4\", model, scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "a6ada983-459e-4545-b79e-34f0df92b2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00619e0-2a7c-40e1-b8ec-88533596b1cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92b7df37-1f84-4153-a292-0677ba255b96",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "991f59e1-3d4b-487c-a931-d2457f5048f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "131de93c-61ef-463c-8dec-84d1cfe44d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid = {\n",
    "    'C': [0.1, 0.5, 1,1.5,  10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436d6586-1cfe-46c9-b706-456f27c17689",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(SVC(), param_grid, cv=5, scoring=\"recall\")\n",
    "\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "y_pred_train = grid.predict(X_train_scaled, )\n",
    "\n",
    "print(\"Accuaracy for training Dataset :- \", accuracy_score(y_pred_train, y_train))\n",
    "print(\"Accuracy for Test Data :- \", accuracy_score(y_pred_test, y_test))\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_pred_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
